\documentclass[doc]{apa6}

\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{kbordermatrix}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}

\usepackage[american]{babel}
\usepackage[style=apa,sortcites=true,sorting=nyt,backend=biber]{biblatex}
\DeclareLanguageMapping{american}{american-apa}
\addbibresource{library.bib}

\newcommand{\subsubsubsection}[1]{\textit{\underline{#1}}}


\title{Notes on EBRW Extension}
\shorttitle{EBRW extension}

\author{Takao Noguchi}
\affiliation{Department of Experimental Psychology, University College London}

\abstract{%

    Here I write down description and math for our EBRW extension. Bits and pieces from this
    document may appear in the later manuscript.

}

\authornote{Last updated: \today.}


\begin{document}

\maketitle


\section{Preliminary}

In this note, I consider a binary classification problem: whether to classify Item $i$ into Category
$\mathbb{A}$ or $\mathbb{B}$. This problem is approached as evidence accumulation processes: at each
time step, evidence is accumulated toward responding as $\mathbb{A}$ or $\mathbb{B}$, and as soon as
the accumulated evidence reaches the boundary, $\theta_{A}$ or $\theta_{B}$, a response is made.

The math derivations below are informed by Chapters 2 and 4 of \textcite{Kijima1997a} and Chapters 2
and 7 of \textcite{Bhat2002a}.

\subsection{Notation}

Free parameters are indicated with Greek letters (e.g., $\rho$), and a matrix and a vector are
indicated with English capital letters (e.g., $Q$), whose element is denoted as a corresponding
small letters (e.g., $q$). The element at $i$th row, $j$th column of $Q$ matrix, for example, is
indicated as $q_{ij}$.


\section{Model Specifications}

\subsection{GCM}

According to \textcite{Nosofsky1986a}'s \emph{generalized context model} (GCM), people represent
categories by storing individual exemplars in memory. Classification decisions are based on summing
the similarity of an object to the exemplars of the alternative categories. In the GCM, exemplars
are represented as points in a multidimensional psychological space, and similarity between
exemplars is a decreasing function of their distance in the space.

Assume the exemplars reside in an multidimensional psychological space, and let $x_{im}$ denote the
value of exemplar $i$ on psychological dimension $m$. The distance between exemplars $i$ and $j$ is
given by
\begin{align}
    d_{ij} = {\left( \sum_{m} \omega_{m} {\vert x_{im} - x_{jm} \vert} ^{\rho} \right)}^{1/\rho},
\end{align}
where $\omega_{m}$ ($0 \leq \omega_{m}, \sum \omega_{m} = 1$) represents the attention weight given
to dimension $m$. The $x_{im}$ psychological coordinate values for the exemplars are generally
derived by conducting multidimensional scaling studies or else are assumed to be given by the
physical coordinate values used for constructing the stimuli.  The attention weights ($\omega_{m}$)
are free parameters in the model.

The distances ($d_{ij}$) are transformed to similarity measures ($s_{ij}$) by using an
exponential decay function:
\begin{align}
    s_{ij} = \exp{(-\gamma \; d_{ij})},
\end{align}
where $\gamma$ is an overall sensitivity parameter for scaling distances in the space.

Because of factors such as recency of presentation, exemplars may reside in memory with differing
strengths. Let $\eta_{j}$ denote the memory strength for exemplar $j$. The degree to which exemplar
$j$ is activated when presented with item $i$ is determined jointly by the exemplar's strength in
memory and by its similarity to item $i$. Specifically, the activation for exemplar $j$ given
presentation of item $i$ ($a_{ij}$) is given by
\begin{align}
    a_{ij} = \eta_{j} \; s_{ij}.
\end{align}

Finally, the evidence for Category $\mathbb{A}$ given presentation of item $i$ is found by summing
the activations for all stored exemplars of Category $\mathbb{A}$. The conditional probability with
which item $i$ is classified into Category $\mathbb{A}$ is found by dividing this evidence by the
summed evidence for all the categories:
\begin{align}
    p(\mathbb{A}) = \frac{\sum_{j \in \mathbb{A}} a_{ij}}
                         {\sum_{j \in \mathbb{A}} a_{ij} + \sum_{j \in \mathbb{B}} a_{ij}}
\end{align}

The GCM does not provides an account of how the exemplar-based similarity comparison process unfolds
over time. Such an account is provided by EBRW\@.


\subsection{EBRW}

In the \emph{exemplar-based random walk} \parencite[EBRW\@;][]{Nosofsky1997a}, there is a random
walk counter that accrues information pointing to either Category $\mathbb{A}$ or $\mathbb{B}$.  The
counter has a starting value of zero; positive increments move it in the direction of Category
$\mathbb{A}$, and negative increments move it in the direction of Category $\mathbb{B}$. The
observer establishes criteria representing the amount of evidence that is needed to execute either a
Category A response ($\theta_{A}$) or a Category B response ($-\theta_{B}$). Once the counter
reaches either of these criteria, the appropriate categorization response is made.

When Item $i$ is presented, it sets off a race among all the exemplars stored in memory. For
simplicity in getting started, and for reasons of analytic tractability, we assume that the race
times are exponentially distributed. Thus, the expected time that Exemplar $j$ completes its race is
given by $\frac{1}{a_{ij}}$, where the activation value ($a_{ij}$) is computed as in the GCM\@.

Also from the GCM, when Item $i$ is presented, the probability that Exemplar $j$ is retrieved is
given by
\begin{align}
    p(j \vert i) = \frac{a_{ij}}
                        {\sum_{j \in \mathbb{A}} a_{ij} + \sum_{j \in \mathbb{B}} a_{ij}.}
\end{align}


\subsubsection{Original formulation (discrete time)}

\begin{figure}[t!]
    \centering
    \includegraphics[width=\textwidth]{figure/ebrw_dt.pdf}

    \vspace{10pt}

    \caption{States in the EBRW model. A gray node is a starting state, and yellow nodes indicate
    absorbing states.}

\label{fig:ebrw_dt}
\end{figure}

The evidence accumulation in the EBRW can be formulated as Markov chain (see
Figure~\ref{fig:ebrw_dt}). This Markov chain has two absorbing states (yellow nodes in
Figure~\ref{fig:ebrw_dt}) and $\theta_{A} + \theta_{B} - 1$ transient states (white and gray nodes).

First, we calculate the probability of taking a step toward Category $\mathbb{A}$ by summing the
probabilities that any one of the exemplars from Category $\mathbb{A}$ is retrieved, yielding
\begin{align}
    p_{A} = \frac{\sum_{j \in \mathbb{A}} a_{ij}}
                 {\sum_{j \in \mathbb{A}} a_{ij} + \sum_{j \in \mathbb{B}} a_{ij}}
\end{align}
Then, the transition matrix for this Markov chain is written with four sub-matrices:
\begin{align}
    P &= \kbordermatrix{%
        &       &        & \\
        & I     & \vrule & 0 \\
        \cline{2-4}
        & R & \vrule & Q\\
      }\\
      &= \kbordermatrix{\mbox{state}
              & \theta_{A} & -\theta_{B} &        & -\theta_{B}-1 & -\theta_{B}-2 & \cdots & -2    & -1    & 0     & 1     & 2     & \cdots & \theta_{A}-2 & \theta_{A}-1\\
\theta_{A}    & 1          & 0           & \vrule & 0             & 0             & \cdots & 0     & 0     & 0     & 0     & 0     & \cdots & 0            & 0     \\
\theta_{B}    & 0          & 1           & \vrule & 0             & 0             & \cdots & 0     & 0     & 0     & 0     & 0     & \cdots & 0            & 0     \\
\cline{2-15}
-\theta_{B}-1 & 0          & p_{B}       & \vrule & 0             & p_{A}         & \cdots & 0     & 0     & 0     & 0     & 0     & \cdots & 0            & 0     \\
-\theta_{B}-2 & 0          & 0           & \vrule & p_{B}         & 0             & \cdots & 0     & 0     & 0     & 0     & 0     & \cdots & 0            & 0     \\
\vdots        &            &             & \vrule &               &               &        &       &       &       &       &       &        &              &       \\
-2            & 0          & 0           & \vrule & 0             & 0             & \cdots & 0     & p_{A} & 0     & 0     & 0     & \cdots & 0            & 0     \\
-1            & 0          & 0           & \vrule & 0             & 0             & \cdots & p_{B} & 0     & p_{A} & 0     & 0     & \cdots & 0            & 0     \\
 0            & 0          & 0           & \vrule & 0             & 0             & \cdots & 0     & p_{B} & 0     & p_{A} & 0     & \cdots & 0            & 0     \\
 1            & 0          & 0           & \vrule & 0             & 0             & \cdots & 0     & 0     & p_{B} & 0     & p_{A} & \cdots & 0            & 0     \\
 2            & 0          & 0           & \vrule & 0             & 0             & \cdots & 0     & 0     & 0     & p_{B} & 0     & \cdots & 0            & 0     \\
\vdots        &            &             & \vrule &               &               &        &       &       &       &       &       &        &              &       \\
\theta_{A}-2  & 0          & 0           & \vrule & 0             & 0             & \cdots & 0     & 0     & 0     & 0     & 0     & \cdots & 0            & p_{A} \\
\theta_{A}-1  & p_{A}      & 0           & \vrule & 0             & 0             & \cdots & 0     & 0     & 0     & 0     & 0     & \cdots & p_{B}        & 0     \\
        }.
\end{align}
A cell located at row $k$ column $j$ of this $P$ matrix represents the probability of going from
state $k$ to state $j$ (note each row in $P$ matrix sums to $1$).  The size of $P$ matrix depends on
the number of transient states: $R$ is a matrix of size $(\theta_{A} + \theta_{B} - 1) \times 2$,
and $Q$ is of size $(\theta_{A} + \theta_{B} - 1) \times (\theta_{A} + \theta_{B} - 1)$.  Here, $R$
is a transition matrix from the transient states to the absorbing states, and $Q$ is a transition
matrix within the transient states. In particular, $Q$ has $p_{A}$ at row $k$ column $k + 1$ and
$p_{B}$ at row $k$ column $k - 1$, and the other cells in $Q$ are all $0$.

Also, we construct a vector, labeled $Z$, representing the starting state of the evidence
accumulation:
\begin{align}
    Z = \kbordermatrix{%
& \theta_{A} & -\theta_{B} & -\theta_{B}-1 & -\theta_{B}-2 & \cdots & -2    & -1    & 0     & 1     & 2     & \cdots & \theta_{A}-2 & \theta_{A}-1\\
& 0          & 0           & 0             & 0             & \cdots & 0     & 0     & 1     & 0     & 0     & \cdots & 0            & 0\\
    }.
\end{align}

The derivation below uses the fundamental matrix ($M$) of this Markov chain, which is given by
\begin{align}
    M &= \left( \sum_{t=1}^{\infty} Q^{t} \right)\\
      &= {\left(I - Q \right)}^{-1}.
\end{align}
Each element in this $M$ matrix is the expected number of visit to each state: the value at the
$k$th row $j$th column ($m_{kj}$) is the expected number of transitions to state $j$, when the chain
started at state $k$.

\subsubsubsection{Response probability.} Then, the probability of classifying Item $i$ into each
category can be computed as follows.
\begin{align}
    \left[p(\mathbb{A}),\; p(\mathbb{B})\right]
        &= Z \; \left( \sum_{t=1}^{\infty} Q^{t} \right) \; R\\
        &= Z \; M \; R.
\end{align}

\subsubsubsection{Alternative response probability.} \textcite{Nosofsky1997a} derived the
response probability as follows:
\begin{align}
    p(\mathbb{A}) = \left\{
            \begin{array}{ll}
            \displaystyle
                \frac{1 - {\left(p_{B}/p_{A}\right)}^{\theta_{B}}}
                     {1 - {\left(p_{B}/p_{A}\right)}^{\theta_{A} + \theta_{B}}}
                     & \mbox{if } p_{A} \neq p_{B} \\
            \vspace{2pt}\\
            \displaystyle
                \frac{\theta_{B}}{\theta_{A} + \theta_{B}}
                    & \mbox{if } p_{A} = p_{B}.
            \end{array}
           \right.
\end{align}
Proof is in Chapter 16 of the book by Feller (1968), but I haven't seen it yet.

\subsubsubsection{Response time.} Before reaching the absorbing states, several exemplars are
retrieved. Here, we derive the expected number of exemplars retrieved by summing elements of $M$
row-wise to derive the total number of exemplars retrieved for each starting state:
\begin{align}
    M_{p} = M \; \left[ \begin{array}{c} 1 \\ 1 \\ \vdots \\ 1 \end{array} \right],
\end{align}
and then, the expectation is given by
\begin{align}
    \mathcal{E}(n) = Z \; M_{p}.
\end{align}
To compute its variance, we first square each element in $M_{p}$
\begin{align}
    M_{p2} = diag{(M_{p})} \; M_{p},
\end{align}
and then the variance is given by
\begin{align}
    \mathcal{V}(n) = Z \; (2 \, M - I) \; M_{p} - M_{p2}.
\end{align}

The expected response time is given by multiplying the expected time to accumulate one piece of
evidence with the expected number of times evidence is accumulated.  Given the property of
exponential distribution, the expected time that at least one exemplar completes its race and
accumulate evidence is
\begin{align}
    \mathcal{E}(\Delta t) = \alpha +
                            \frac{1}
                                {\sum_{j \in \mathbb{A}} a_{ij} + \sum_{j \in \mathbb{B}} a_{ij},}
\end{align}
where $\alpha$ is a step-time constant. Then,
\begin{align}
    \mathcal{E}(t) = \mathcal{E}(\Delta t) \; \mathcal{E}(n).
\end{align}

\subsubsubsection{Alternative response time.} \textcite{Nosofsky1997a} derived the response time
as follows:
\begin{align}
    \mathcal{E}(n) = \left\{
        \begin{array}{ll}
            \displaystyle
                \frac{\theta_{B}}{p_{B} - p_{A}} - \frac{\theta_{A} + \theta_{B}}{p_{B} - p_{A}}
                \left[
                \frac{1 - {\left(p_{B}/p_{A}\right)}^{\theta_{B}}}
                     {1 - {\left(p_{B}/p_{A}\right)}^{\theta_{A} + \theta_{B}}}
                \right] & \mbox{if } p_{A} \neq p_{B} \\
            \vspace{2pt}\\
            \displaystyle
                \theta_{A} \, \theta_{B}
                    & \mbox{if } p_{A} = p_{B}.
        \end{array}
    \right.
\end{align}
Proof is in Chapter 16 of the book by Feller (1968), but I haven't seen it yet.

\textcite{Nosofsky1997a} also derived the response time conditioned on a response: the response
time given a category response of $\mathbb{A}$ is
\begin{align}
    \mathcal{E}(n \vert \mathbb{A}) = \left\{
        \begin{array}{ll}
            \displaystyle
            \frac{1}{p_{A} - p_{B}} \left[
                \frac{{\left(p_{A} / p_{B} \right)}^{\theta_{A} + \theta_{B}} + 1}
                     {{\left(p_{A} / p_{B} \right)}^{\theta_{A} + \theta_{B}} - 1}
                (\theta_{A} + \theta_{B}) -
                \frac{{\left(p_{A} / p_{B} \right)}^{\theta_{B}} + 1}
                     {{\left(p_{A} / p_{B} \right)}^{\theta_{B}} - 1}
                \theta_{B}
                \right] & \mbox{if } p_{A} \neq p_{B} \\
            \displaystyle
            \frac{\theta_{A}}{3}\left(2\, \theta_{B} + \theta_{A} \right)
                & \mbox{if } p_{A} = p_{B}.
        \end{array}
    \right.
\end{align}
Similarly,
\begin{align}
    \mathcal{E}(n \vert \mathbb{B}) = \left\{
        \begin{array}{ll}
            \displaystyle
            \frac{1}{p_{B} - p_{A}} \left[
                \frac{{\left(p_{A} / p_{B} \right)}^{-\theta_{A} + \theta_{B}} + 1}
                     {{\left(p_{A} / p_{B} \right)}^{-\theta_{A} - \theta_{B}} - 1}
                (\theta_{A} + \theta_{B}) -
                \frac{{\left(p_{A} / p_{B} \right)}^{-\theta_{A}} + 1}
                     {{\left(p_{A} / p_{B} \right)}^{-\theta_{A}} - 1}
                \theta_{B}
                \right] & \mbox{if } p_{A} \neq p_{B} \\
            \displaystyle
            \frac{\theta_{B}}{3}\left(2\, \theta_{A} + \theta_{B} \right)
                & \mbox{if } p_{A} = p_{B}.
        \end{array}
    \right.
\end{align}
Proof is in \textcite{Busemeyer1982a}, but I haven't checked it yet.

\subsubsubsection{Alternative response time 2.} \textcite{Diederich2003a} used an alternative
derivation to compute the expected number of exemplars, conditioned on a response. Proof is
supposedly in \textcite{Diederich1995a}, but I haven't found it yet.

\begin{align}
    [\mathcal{E}(n \vert \mathbb{A}), \; \mathcal{E}(n \vert \mathbb{B})]
        &= \left( \sum_{t=1}^{\infty} t \, Z \; Q^{t} \; R \right) \;
        {\left[ \begin{array}{cc} p(A \vert i) & 0 \\ 0 & p(B \vert i) \end{array} \right]}^{-1}\\
        &= Z \; \left( \sum_{t=1}^{\infty} t \, Q^{t} \right) \; R \;
        {\left[ \begin{array}{cc} p(A \vert i) & 0 \\ 0 & p(B \vert i) \end{array} \right]}^{-1}\\
        &= Z \; {(I - Q)}^{-2} \; R \;
        {\left[ \begin{array}{cc} p(A \vert i) & 0 \\ 0 & p(B \vert i) \end{array} \right]}^{-1}.
\end{align}


\subsubsection{EBRWd: Markov chain formulation (discrete time)}

One potential limitation of the above Markov chain formulation is in response time computation. It
considers only the expected retrieval time for all the exemplars. This limitation may be significant
when the retrieval time is systematically different between exemplars: for example, one exemplar
from Category $\mathbb{A}$ is much faster to retrieve while on average, the exemplars from Category
$\mathbb{A}$ is much slower to retrieve. To overcome this limitation, we consider time to retrieve
individual exemplars in the EBRW model.

\begin{figure}[t!]
    \centering
    \includegraphics[width=\textwidth]{figure/ebrw_ct.pdf}

    \vspace{10pt}

    \caption{A state is characterized by accumulated evidence and the last exemplar retrieved. A
    gray node is a starting state, and yellow nodes indicate absorbing states.}

\label{fig:ebrw_ct}
\end{figure}

As we consider retrieval of individual exemplars here, a state in Markov chain is now characterized
by both evidence accumulated and the last retrieved exemplar. These states are illustrated in
Figure~\ref{fig:ebrw_ct}. This Markov chain has $(n + n') \, (\theta_{B} + \theta_{A} - 1) + 1$
transient states, where $n$ is the number of exemplars in Category $\mathbb{A}$ and $n'$ is the
number of exemplars in Category $\mathbb{B}$.  Similarly, the number of absorbing states is now $n +
n'$.

The transition matrix is formulated as above:
\begin{align}
    P_{d} = \kbordermatrix{%
        &       &        & \\
        & I     & \vrule & 0 \\
        \cline{2-4}
        & R_{d} & \vrule & Q_{d} \\
      },
\end{align}
where $R_{d}$ is of size $\left((n + n') \, (\theta_{B} + \theta_{A} - 1) + 1 \right) \times (n + n')$
and $Q_{d}$ is a square matrix. Specifically,
\begin{align}
    R_{d} = \kbordermatrix{%
\mbox{state}         & \theta_{A}, x_{1} & \theta_{A}, x_{2} & \cdots & \theta_{A}, x_{n} & \theta_{B}, x_{1'} & \theta_{B}, x_{2'} & \cdots & \theta_{B}, x_{n'} \\
\theta_{B}-1, x_{1'} & 0                 & 0                 & \cdots & 0                 & p(1' \vert i)      &  p(2' \vert i)     & \cdots &  p(n' \vert i) \\
\theta_{B}-1, x_{2'} & 0                 & 0                 & \cdots & 0                 & p(1' \vert i)      &  p(2' \vert i)     & \cdots &  p(n' \vert i) \\
\vdots               & \vdots            & \vdots            &        & \vdots            & \vdots             & \vdots             &        & \vdots \\
\theta_{B}-1, x_{n'} & 0                 & 0                 & \cdots & 0                 & p(1' \vert i)      &  p(2' \vert i)     & \cdots &  p(n' \vert i) \\
\theta_{B}-2, x_{1}  & 0                 & 0                 & \cdots & 0                 & 0                  & 0                  & \cdots & 0 \\
\theta_{B}-2, x_{2}  & 0                 & 0                 & \cdots & 0                 & 0                  & 0                  & \cdots & 0 \\
\vdots               & \vdots            & \vdots            &        & \vdots            & \vdots             & \vdots             &        & \vdots \\
\theta_{A}-2, x_{n'} & 0                 & 0                 & \cdots & 0                 & 0                  & 0                  & \cdots & 0 \\
\theta_{A}-1, x_{1}  & p(1 \vert i)      & p(2 \vert i)      & \cdots & p(n \vert i)      & 0                  & 0                  & \cdots & 0 \\
\theta_{A}-1, x_{2}  & p(1 \vert i)      & p(2 \vert i)      & \cdots & p(n \vert i)      & 0                  & 0                  & \cdots & 0 \\
\vdots               & \vdots            & \vdots            &        & \vdots            & \vdots             & \vdots             &        & \vdots \\
\theta_{A}-1, x_{n}  & p(1 \vert i)      & p(2 \vert i)      & \cdots & p(n \vert i)      & 0                  & 0                  & \cdots & 0 \\
    },
\end{align}
and
\begin{align}
    Q_{d} = \kbordermatrix{\mbox{state}
          & \cdots  & -1, x_{1'}    & -1, x_{2'}    & \cdots & -1, x_{n'}    & \cdots & 0, x_{1} & 0, x_{2} & \cdots & 0, x_{n} & \cdots & 1, x_{1}     & 1, x_{2}     & \cdots & 1, x_{n}     & \cdots \\
\vdots    &         & \vdots        & \vdots        &        & \vdots        &        & \vdots   & \vdots   &        & \vdots   &        & \vdots       & \vdots       &        & \vdots       &  \\
0, x_{1}  &         & p(1' \vert i) & p(2' \vert i) & \cdots & p(n' \vert i) & \cdots & 0        & 0        & \cdots & 0        & \cdots & p(1 \vert i) & p(2 \vert i) & \cdots & p(n \vert i) & \\
0, x_{2}  &         & p(1' \vert i) & p(2' \vert i) & \cdots & p(n' \vert i) & \cdots & 0        & 0        & \cdots & 0        & \cdots & p(1 \vert i) & p(2 \vert i) & \cdots & p(n \vert i) & \\
\vdots    &         & \vdots        & \vdots        &        & \vdots        &        & \vdots   & \vdots   &        & \vdots   &        & \vdots       & \vdots       &        & \vdots       &  \\
0, x_{n}  &         & p(1' \vert i) & p(2' \vert i) & \cdots & p(n' \vert i) & \cdots & 0        & 0        & \cdots & 0        & \cdots & p(1 \vert i) & p(2 \vert i) & \cdots & p(n \vert i) & \\
\vdots    &         & \vdots        & \vdots        &        & \vdots        &        & \vdots   & \vdots   &        & \vdots   &        & \vdots       & \vdots       &        & \vdots       &  \\
        }.
\end{align}
As defined above, $p(j \vert i)$ is the probability of retrieving Exemplar $j$ using Item $i$ as a cue. Each row in $P_{d}$ matrix sums to $1$.

\subsubsubsection{Response probability.} Then as above, the fundamental matrix is given by
\begin{align}
    M_{d} = {\left(I - Q_{d} \right)}^{-1},
\end{align}
and the probability of reaching the absorbing states is
\begin{align}
    \left[(\theta_{A}, x_{1}),  (\theta_{A}, x_{2}),  \ldots, (\theta_{A}, x_{n}),
        (\theta_{B}, x_{1'}), (\theta_{B}, x_{2'}), \ldots, (\theta_{B}, x_{n'})\right]
    = Z \; M_{d} \; R_{d}.
\end{align}
The probability of classifying Item $i$ into each category is given by summing the probabilities of
appropriate absorbing states:
\begin{align}
    [p(\mathbb{A}), \; p(\mathbb{B})] =
        Z \; M_{d} \; R_{d}
        \left[
            \begin{array}{cc}
                1      & 0      \\
                1      & 0      \\
                \vdots & \vdots \\
                1      & 0      \\
                0      & 1      \\
                0      & 1      \\
                \vdots & \vdots \\
                0      & 1      \\
            \end{array}
        \right].
\end{align}

\subsubsubsection{Response time.} As the fundamental matrix ($M_{d}$) is the expected number of times each exemplar is retrieved, we first multiply each element in $M_{d}$ with the expected retrieval time for each exemplar:
\begin{align}
    \mathcal{E}(t_{.(z, j)}) = \left( \alpha + \frac{1}
                                                    {\sum_{j \in \mathbb{A}} a_{ij} + \sum_{j \in \mathbb{B}} a_{ij}}
                               \right) \; m_{.(z, j)}.
\end{align}
Then the expected response time is given by summing the relevant elements:
\begin{align}
    \mathcal{E}(t) = Z \; T \; \left[ \begin{array}{c} 1 \\ 1 \\ \vdots \\ 1 \end{array} \right].
\end{align}


\subsubsection{EBRWc: Markov process formulation (continuous time)}

In addition, we formulate the EBRW with Markov process (continuous time). As in the EBRWd, the EBRWc has $(n + n') \, (\theta_{B} + \theta_{A} - 1) + 1$ transient states, and $n + n'$ absorbing states.

In the EBRWc, we consider transition rates, instead of transition probabilities.  The rate matrix is written with four sub-matrices:
\begin{align}
    P_{c} = \kbordermatrix{%
        &       &        & \\
        & 0     & \vrule & 0 \\
        \cline{2-4}
        & R_{c} & \vrule & Q_{c}\\
      },
\end{align}
where $R_{c}$ is of size $\left((n + n') \, (\theta_{B} + \theta_{A} - 1) + 1 \right) \times (n +
n')$ and $Q_{c}$ is a square matrix. Specifically,
\begin{align}
    R_{c} = \kbordermatrix{%
\mbox{state}         & \theta_{A}, x_{1} & \theta_{A}, x_{2} & \cdots & \theta_{A}, x_{n} & \theta_{B}, x_{1'} & \theta_{B}, x_{2'} & \cdots & \theta_{B}, x_{n'} \\
\theta_{B}-1, x_{1'} & 0                 & 0                 & \cdots & 0                 & a_{i1'}            & a_{i2'}            & \cdots & a_{in'} \\
\theta_{B}-1, x_{2'} & 0                 & 0                 & \cdots & 0                 & a_{i1'}            & a_{i2'}            & \cdots & a_{in'} \\
\vdots               & \vdots            & \vdots            &        & \vdots            & \vdots             & \vdots             &        & \vdots \\
\theta_{B}-1, x_{n'} & 0                 & 0                 & \cdots & 0                 & a_{i1'}            & a_{i2'}            & \cdots & a_{in'} \\
\theta_{B}-2, x_{1}  & 0                 & 0                 & \cdots & 0                 & 0                  & 0                  & \cdots & 0 \\
\theta_{B}-2, x_{2}  & 0                 & 0                 & \cdots & 0                 & 0                  & 0                  & \cdots & 0 \\
\vdots               & \vdots            & \vdots            &        & \vdots            & \vdots             & \vdots             &        & \vdots \\
\theta_{A}-2, x_{n'} & 0                 & 0                 & \cdots & 0                 & a_{i1'}            & a_{i2'}            & \cdots & a_{in'} \\
\theta_{A}-1, x_{1}  & a_{i1}            & a_{i2}            & \cdots & a_{in}            & 0                  & 0                  & \cdots & 0 \\
\theta_{A}-1, x_{2}  & a_{i1}            & a_{i2}            & \cdots & a_{in}            & 0                  & 0                  & \cdots & 0 \\
\vdots               & \vdots            & \vdots            &        & \vdots            & \vdots             & \vdots             &        & \vdots \\
\theta_{A}-1, x_{n}  & a_{i1}            & a_{i2}            & \cdots & a_{in}            & 0                  & 0                  & \cdots & 0 \\
    },
\end{align}
and
\begin{align}
    Q_{c} = \kbordermatrix{\mbox{state}
          & \cdots  & -1, x_{1'} & -1, x_{2'} & \cdots & -1, x_{n'} & \cdots & 0, x_{1} & 0, x_{2} & \cdots & 0, x_{n} & \cdots & 1, x_{1} & 1, x_{2} & \cdots & 1, x_{n} & \cdots \\
\vdots    &         & \vdots     & \vdots     &        & \vdots     &        & \vdots   & \vdots   &        & \vdots   &        & \vdots   & \vdots   &        & \vdots   &  \\
0, x_{1}  &         & a_{i1'}    & a_{i2'}    & \cdots & a_{in'}    & \cdots & \lambda  & 0        & \cdots & 0        & \cdots & a_{i1}   & a_{i2}   & \cdots & a_{in}   & \\
0, x_{2}  &         & a_{i1'}    & a_{i2'}    & \cdots & a_{in'}    & \cdots & 0        & \lambda  & \cdots & 0        & \cdots & a_{i1}   & a_{i2}   & \cdots & a_{in}   & \\
\vdots    &         & \vdots     & \vdots     &        & \vdots     &        & \vdots   & \vdots   & \ddots & \vdots   &        & \vdots   & \vdots   &        & \vdots   &  \\
0, x_{n}  &         & a_{i1'}    & a_{i2'}    & \cdots & a_{in'}    & \cdots & 0        & 0        & \cdots & \lambda  & \cdots & a_{i1'}  & a_{i2}   & \cdots & a_{in}   & \\
\vdots    &         & \vdots     & \vdots     &        & \vdots     &        & \vdots   & \vdots   &        & \vdots   &        & \vdots   & \vdots   &        & \vdots   &  \\
        }.
\end{align}
A cell located at row $k$ column $j$ of this $P_{c}$ matrix represents the rate of going to state
$j$, that is, the rate of retrieving Exemplar $j$, $a_{ij}$.  Also, the diagonal entries in $Q_{c}$
is a negated sum of all the rates:
\begin{align}
    \lambda = - \left(\sum_{j=1}^{n} a_{ij} + \sum_{j=1'}^{n'} a_{ij} \right).
\end{align}
Thus, each row in $P_{c}$ matrix sums to $0$.


\subsubsubsection{Response probability.} To compute the response probability, we first note that the
matrix multiplication leads us to
\begin{align}
    P_{c}^{n} = \left[
        \begin{array}{cc}
            0                    & 0 \\
            Q_{c}^{n-1} \; R_{c} & Q_{c}^{n}\\
        \end{array}
    \right], \quad n = 1, 2, \dots.
\end{align}
Then we derive probability of each state after time $t$ ($t > 0$) has passed:
\begin{align}
    F(t) &= \exp{(P_{c} \; t)} \quad \because \mbox{Solution to Kolmogorov equations}\\
         &= \sum_{n=0}^{\infty} \frac{P_{c}^{n} \; t^{n}}{n!} \quad \because \mbox{Taylor approximation}\\
         &= I + \sum_{n=1}^{\infty} \frac{P_{c}^{n} \; t^{n}}{n!} \\
         &= \kbordermatrix{%
            &          & \\
            & I        & 0 \\
            & R_{c}(t) & Q_{c}(t) \\
        },
\end{align}
where the transition probability within the transient states is
\begin{align}
    Q_{c}(t) &= \sum_{n=0}^{\infty} \frac{Q_{c}^{n} \; t^{n}}{n!}\\
             &= \exp{(Q_{c} \; t)},
\end{align}
and the transition probability from the transient states to the abosorbing states is
\begin{align}
    R_{c}(t) &= \int_{0}^{t} Q_c{(u)} \; R_{c} \, du \\
             &= \left( \int_{0}^{t} Q_c{(u)} \, du \right) \; R_{c}.
\end{align}

The probability for the absorbing state is derived by letting $t \rightarrow \infty$.
\begin{align}
    \lim_{t \rightarrow \infty} Q_{c}(t) = 0
\end{align}
and
\begin{align}
    \lim_{t \rightarrow \infty} R_{c}(t) &= \left( \int_{0}^{\infty} Q_c{(u)} \, du \right) \; R_{c}\\
                                         &= - Q_{c}^{-1} \; R_{c}.
\end{align}
Thus
\begin{align}
    \lim_{t \rightarrow \infty} F(t) = \left[
        \begin{array}{cc}
            I & 0 \\
            - Q_{c}^{-1} \; R_{c} & 0
        \end{array}
    \right].
\end{align}
Then, the probability of reaching the absorbing states is given by
\begin{align}
\left[(\theta_{A}, x_{1}),  (\theta_{A}, x_{2}),  \ldots, (\theta_{A}, x_{n}),
      (\theta_{B}, x_{1'}), (\theta_{B}, x_{2'}), \ldots, (\theta_{B}, x_{n'})\right]
= Z \; \left[
        \begin{array}{c}
            I \\ - Q_{c}^{-1} \; R_{c}
        \end{array}
    \right].
\end{align}
The probability of classifying Item $i$ into each category is given by summing the probabilities of
appropriate absorbing states:
\begin{align}
    [p(\mathbb{A}), \; p(\mathbb{B})] =
        Z \; \left[
        \begin{array}{c}
            I \\ - Q_{c}^{-1} \; R_{c}
        \end{array}
    \right] \;
        \left[
            \begin{array}{cc}
                1      & 0      \\
                1      & 0      \\
                \vdots & \vdots \\
                1      & 0      \\
                0      & 1      \\
                0      & 1      \\
                \vdots & \vdots \\
                0      & 1      \\
            \end{array}
        \right].
\end{align}

\subsubsubsection{Response time.} The expected time spent on a transient state is given by
\begin{align}
    \int_{0}^{\infty} Q_{c}(t) \, dt &= - Q_{c}^{-1}.
\end{align}
Similarly to the fundamental matrix for the Markov chain ($M$ above), each element in this matrix
represents the expected time spent on each state: a cell at the $k$th row $j$th column corresponds
to the time spent on state $j$, when the starting state is $k$. Thus, time required to reach a
response boundary is given by
\begin{align}
    \mathcal{E}(t) = - Z \; Q_{c}^{-1} \; \left[ \begin{array}{c} 1\\1\\\vdots\\1 \end{array} \right].
\end{align}


\subsection{SSM\@: Sequential sampling model}

The EBRW model assumes that people use only the target item (Item $i$ in above). However, previous
research on free recall has demonstrated that memory retrieval is not an independent process.
Rather, memory retrieval is sequence dependent, and here, we implement the first-order Markov chain
in retrieval process. That is, the probability of retrieving exemplar $j$ also depends on its
similarity to the last exemplar retrieved from memory. In particular, we parameterize the model such
that at each step of evidence accumulation, people use the last retrieved exemplar as a cue to
retrieve a next exemplar with probability $\psi$, and with probability $1 - \psi$, people use the
target item as a cue.

Unlike the target item, which is to be classified, the last retrieved exemplar has its category
label available as well as its features. Thus when the last retrieved exemplar is used as a cue,
people may consider its category label and are more likely to retrieve an exemplar from the same
category. We implement this possibility by revising the distance between exemplars. Specifically,
when the last retrieved exemplar is $k$,
\begin{align}
    d_{kj} = {\left( \omega_{l} \; 1_{\{y_k = y_j\}} + \sum_{m} \omega_{m} \, {\vert x_{im} - x_{jm}
    \vert} ^{\rho} \right)}^{1/\rho},
\end{align}
where $y_k$ is the category label of Exemplar $k$, and $0 \leq \omega_{l}$, $0 \leq \omega_{m}$,
and $\omega_{l} + \sum \omega_{m} = 1$.


\subsubsection{SSMd: Markov chain formulation (discrete time)}

As in the EBRWd, each state is characterized by evidence accumulated and the last retrieved
exemplar. Thus, the number of transient state is $(n + n') \, (\theta_{B} + \theta_{A} - 1) + 1$ and
the number of absorbing states is $n + n'$.  The probability of transitioning from state $(0, k)$ to
state $(+1, j)$ by retrieving Exemplar $j$ in Category $\mathbb{A}$ is now
\begin{align}
    p_{(0,k)(+1,j)} = \psi \frac{a_{kj}}{\sum_{j} a_{kj}}  +
                      (1 - \psi) \frac{a_{ij}}{\sum_{j} a_{ij}.}
\end{align}
We also divide the transition matrix $P$ into four sub-matrices just as we did for the EBRWd. The
rest of derivation is the same as that for the EBRWd.


\subsubsection{SSMc: Markov process formulation (continuous time)}

Similarly with the Markov process formulation, the rate to transition from state $(0,k)$, where Exemplar
$k$ is last retrieved, to state $(+1,j)$ by retrieving Exemplar $j$ from Category $\mathbb{A}$ is
\begin{align}
    p_{(0,k)(+1,j)} = \psi \; a_{jk} + (1 - \psi) \; a_{ik}.
\end{align}
{\color{red} [I'm not sure if this is correct.]}
The rest of derivation is the same as that for the EBRWc.


\section{Model Parameters}

\begin{figure}
    \centering
    \includegraphics[]{../simulate_models/figure/parameter_prior.pdf}

    \caption{Prior density/mass function.}

\label{fig:parameter_prior}
\end{figure}

I arbitrarily defined prior distributions for the model parameters. Prior density is illustrated in
Figure~\ref{fig:parameter_prior}. The following simulations were conditioned on this prior
distribution.

\smallskip
\noindent \emph{EBRWd, EBRWc, SSMd, and SSMc}\\
\indent Attention weight for item-exemplar similarity (two dimension): $\omega_{item} \sim Dir(50, 50)$\\
\indent Similarity kernel parameter: $\rho \sim Gamma(13,\, 0.1)$\\
\indent Similarity gradient: $\gamma \sim Gamma(15,\, 0.2)$\\
\indent Memory strength: $\eta = 1$\\
\indent Response boundary: $\theta - 1 \sim Poisson(3)$

\smallskip
\noindent \emph{EBRWd and SSMd}\\
\indent Time to accumulate evidence after retrieving an exemplar: $\alpha \sim Expon(1)$

\smallskip
\noindent \emph{SSMd and SSMc}\\
\indent Attention weight for exemplar-exemplar similarity (two dimension):\\
\indent \indent $\omega_{exemplar} \sim Dir(5, 5, 90)$\\
\indent Probability of using the last retrieved exemplar as a cue: $\psi \sim Beta(19,\, 3)$


\section{Simulation}

\subsection{Symmetric categories}

In this section, I compare the models to examine (1) whether the discrete time formulation differs
from the continuous time formulation, and (2) how the SSM differs from the EBRW\@. In each simulation,
I first randomly drew 10 exemplars for each category from Gaussian distribution:
\begin{align}
    \mathbb{A}: x_{j} &\sim \mathcal{N}\left(
        \left[ \begin{array}{c} -1\\-1 \end{array} \right], \;
        \left[ \begin{array}{c c} 1&0\\0&1 \end{array} \right]
        \right) \quad j = 1, 2, \dots, 5 \quad \mbox{and}\\
    \mathbb{B}: x_{j'} &\sim\mathcal{N}\left(%
        \left[ \begin{array}{c} 1\\1 \end{array} \right], \;
        \left[ \begin{array}{c c} 1&0\\0&1 \end{array} \right]
        \right) \quad j = 1, 2, \dots, 5.
\end{align}
Then, model predictions on $[0, 0]$ were compared with 200 parameters drawn from the prior. Ten
sets of exemplars were tested.

\begin{figure}[h!]
    \includegraphics[]{../simulate_models/figure/sym_pA.pdf}

    \caption{Response probability for the symmetric categories. Dot is a median prediction, and
    error bar is 95\% highest density interval.}

\label{fig:sym_pA}
\end{figure}

Figure~\ref{fig:sym_pA} summarizes predicted response probability for Category $\mathbb{A}$. This
figure illustrates that predictions with the discrete time formulation does not differ much from
predictions with the continuous time formulation: EBRWd's predictions are quite similar to EBRWc's
predictions, and SSMd's predictions are quite similar to SSMc's prediction. Also, the prediction
with SSM tends to be closer to $.50$, compared to the predictions with EBRW\@.


\subsection{Asymmetric categories}

\begin{figure}
    \centering
    \includegraphics[]{../simulate_models/figure/asym_category.pdf}

    \caption{Distributions of two category exemplars. The category distributions are $Gamma(1, 1)$
    for Category $\mathbb{A}$ and $\mathcal{N}(4, 0.1)$ for Category $\mathbb{B}$. Vertical lines
    represent mean of distribution, and $x$ indicates a value of the probe item.}

\label{fig:asym_category}
\end{figure}

Further I examined models with asymmetric category structures. Here, an exemplar is characterized by
only one feature (as opposed to two features above). As above, 10 exemplars were drawn from Category
$\mathbb{A}$ distribution and another 10 were drawn from Category $\mathbb{B}$ distribution.
Figure~\ref{fig:asym_category} illustrates the category distributions. Importantly, the probe item
is closer to the mean of Category $\mathbb{B}$ distribution, but most similar exemplar tends to come
from Category $\mathbb{A}$.  The parameter values are drawn from the same distributions as above,
and each set of exemplars was tested with 200 sets of parameter values.

\begin{figure}[h!]
    \includegraphics[]{../simulate_models/figure/asym_pA.pdf}

    \caption{Response probability for the symmetric categories. Dot is a median prediction, and
    error bar is 95\% highest density interval.}

\label{fig:asym_pA}
\end{figure}

Figure~\ref{fig:asym_pA} summarizes predicted response probability for Category $\mathbb{A}$. This
figure illustrates that predictions with the discrete time formulation does not differ much from
predictions with the continuous time formulation. Also, the prediction with SSM tends to be closer
to $.50$, compared to the predictions with EBRW\@. All the models, however, predict Category
$\mathbb{B}$ response, implying that the EBRWd and EBRWc are difficult to behaviorally differentiate
from the SSMd and SSMc.


\subsection{Asymmetric categories 2}

Thus far, the simulations have shown that the models make similar predictions. This similarity may
be due to the category distributions, not due to the models themselves. In this section, I manually
specified a set of exemplars to exaggerate differences between the models.  Specifically, the
exemplars are:
\begin{align}
    \mathbb{A}&: \{-1.0, -0.9, -0.8, -0.7, -0.6, -0.5, -0.4, -0.3, -0.2, -0.1\}\\
    \mathbb{B}&: \{0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49\}.
\end{align}
The probe item was $[0.0]$. Importantly, the probe item is most similar to an exemplar from Category
$\mathbb{A}$ but is closer to the mean of Category $\mathbb{B}$ ($0.445$) than to the mean of Category
$\mathbb{A}$ ($-0.55$). Thus, I expected the EBRW to predict Category $\mathbb{B}$ response and the
SSM to predict Category $\mathbb{A}$ response.

\begin{figure}[h!]
    \includegraphics[]{../simulate_models/figure/asym2_pA.pdf}

    \caption{Response probability for the symmetric categories 2. Dot is a median prediction, and
    error bar is 95\% highest density interval.}

\label{fig:asym2_pA}
\end{figure}

The simulation results, however, show that all the models are rather indifferent between the two
categories (see Figure~\ref{fig:asym2_pA}), and again the predictions are too similar to
differentiate.


\subsection{5--4 problem}

For the 5--4 problem \parencite{Medin1978a}, I revised the prior for attention weight ($\omega$) to
reflect the optimal attention weight \parencite{Lamberts1995a}: for item-exemplar similarity,
\begin{align}
    \omega_{item} \sim Dir(33, 3, 33, 31),
\end{align}
and for exemplar-exemplar similarity (for SSM),
\begin{align}
    \omega_{exemplar} \sim Dir(3.3, 0.3, 3.3, 3.1, 90).
\end{align}

\begin{figure}[h!]
    \includegraphics[]{../simulate_models/figure/five_four_pA.pdf}

    \caption{Response probability for the symmetric categories 2. Dot is a median prediction for
    each transfer item, and error bar is 95\% highest density interval.}

\label{fig:five_four_pA}
\end{figure}

The simulation results show the same pattern as above: compared to the EBRW's predictions, the SSM
predicts response probability closer to $.50$ (see Figure~\ref{fig:five_four_pA}). Again, the models
do not make competing predictions.



\printbibliography{}
\end{document}
