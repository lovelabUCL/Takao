\documentclass[11pt,a4paper]{article}
% \documentclass[man,floatsintext]{apa6}
% \documentclass[doc]{apa6}

\usepackage[margin=2.5cm]{geometry}
\setlength{\parskip}{0.8\baselineskip}

\usepackage{amsmath}
\usepackage{amsfonts}

% Remove numbering on footnote
\renewcommand\footnotemark{}

\usepackage{titlesec}
\titleformat*{\section}{\Large\bfseries}
\titleformat*{\subsection}{\large\bfseries}


\begin{document}

{\let\thefootnote\relax\footnotetext{%

Questions concerning this document should be directed to Takao Noguchi (t.noguchi@ucl.ac.uk).

Last updated: \today.
}}

\begin{center}
    \textbf{\LARGE RewCon Modeling Summary}
\end{center}

The rational model of categorization (RMC\@; Anderson, 1991) was fitted to participants' responses
during the training phase. In particular, we used the particle filter version of the RMC (Sanborn,
Griffiths, \& Navarro, 2010). The modeling exercise is summarized in this document. First, I briefly
describe the RMC, with the aim to introduce notations I use to describe model-based estimates.


\section{Model --- Rational model of categorization (RMC)}

Suppose a learner has observed $n - 1$ objects $\left\{x_{1}, x_{2}, \dots, x_{n - 1}\right\}$ with
corresponding category labels $\left\{y_{1}, y_{2}, \dots, y_{n - 1}\right\}$. In the RewCon
experiment, $x_{i}$ is a pair of cues presented in the $i$th trial, and $y_{i}$ is a corresponding
category (hat or glove).  Exemplar (e.g., green hat or black glove) is denoted as $y_{i}'$. In the
RMC, each of these objects fits into a mental cluster. The cluster label for the $i$th object is
denoted as $z_{i}$.

\subsection{Drawing an inference with the RMC}

Then, the probability that the $n$th object fits into category $w$ is expressed as follows:
\begin{align}
    p(y_{n} = w \; \vert \; x_{n})
    &= \sum_{k \in \mathbb{Z}} p(z_{n} = k \; \vert \; x_{n}) \; p(y_{n} = w \; \vert \; z_{n} = k) \notag\\
    &= \sum_{k \in \mathbb{Z}} \; \frac{p(z_{n} = k) \; p(x_{n} \;\vert\; z_{n} = k)}{p(x_{n})} \; p(y_{n} = w \; \vert \; z_{n} =
    k) \notag\\
    &= \sum_{k \in \mathbb{Z}} \; \frac{p(z_{n} = k) \; p(x_{n} \;\vert\; z_{n} = k)}{\sum_{s \in
    \mathbb{Z}} \; p(z_{n} = s) \; p(x_{n} \;\vert\; z_{n} = s)} \; p(y_{n} = w \; \vert \; z_{n} = k).
\label{eqn:inference}
\end{align}
Here, $\mathbb{Z}$ is a set of all the possible clusters to which the $n$th object can be assigned.
The three terms in Equation~\ref{eqn:inference} are described below in turn.

First, the probability that the $n$th object fits into a cluster $k$ is given by:
\begin{align}
    p(z_{n} = k) = \left\{
        \begin{array}{rcl}
            \displaystyle \frac{c\,m_{k}}{(1 - c) + c\,(n - 1)} & \mbox{if} & m_{k} > 0\\
            \\
            \displaystyle \frac{(1 - c)}{(1 - c) + c\,(n - 1)} & \mbox{if} & m_{k} = 0
        \end{array}
    \right.
\label{eqn:prior}
\end{align}
where $c$ is a parameter called the coupling probability and $m_{k}$ is the number of objects
assigned into cluster $k$.

Following Anderson (1991) and Sanborn et al.\ (2010), we assume that an object has independent
dimensions. Therefore,
\begin{align}
    p(x_{n} \; \vert \; z_{n} = k) = \prod_{d \in D} p(x_{n,d} \; \vert \; z_{n} = k),
\label{eqn:feature1}
\end{align}
where $D$ is a set of dimensions in which an object is described (i.e., first and second cues).
The above term is computed with
\begin{align}
    p(x_{n,d} = v \; \vert \; z = k) = \frac{B_{v,d} + \beta_{c}}{m_{k} + J_{d} \, \beta_{c}},
\label{eqn:feature2}
\end{align}
where $B_{v,d}$ is the number of objects in cluster $k$ with value of $v$ on dimension $d$, and
$J_{d}$ is the number of values which an object can take on dimension $d$ (i.e., four in the
RewCon).

Similarly, the probability that the $n$th object has category label $w$, given a cluster, is given by:
\begin{align}
    p(y_{n} = w \; \vert \; z = k) = \frac{B_{w} + \beta_{l}}{B_{.} + J \, \beta_{l}},
\label{eqn:label}
\end{align}
where $B_{w}$ is the number of observed objects with category label $w$ in cluster $k$, $B_{.}$ is
the number of object in cluster $k$, and $J$ is the number of category labels.


\subsection{Learning with the RMC}

The learning in the RMC is to assign an object into a cluster. The cluster assignment at the $n$th
trial, for example, is performed with the probability of each cluster. The probability that an
object fits into cluster $k$ is computed as
\begin{align}
    p(z_{n} = k \;\vert\; x_{n},\, y_{n},\, y_{n}') \propto
    p(z_{n} = k)
    \;
    p(x_{n} \;\vert\; z_{n} = k)
    \;
    p(y_{n} \;\vert\; z_{n} = k)
    \;
    p(y_{n}' \;\vert\; z_{n} = k).
\label{eqn:learning}
\end{align}
This is computed with Equations~\ref{eqn:prior},~\ref{eqn:feature1} and~\ref{eqn:label}.


\subsection{Parameter Estimation}

The RMC, when applied to the RewCon experiment, has four parameters: coupling probability $c$,
sensitivity parameter for cues $\beta_{c}$, sensitivity parameter for category label $\beta_{l}$,
and sensitivity parameter for exemplar $\beta_{e}$. Following Sanborn et al.\ (2010), the number of
particle is set to 1.

We estimated the most likely parameter values given participants' behavioral responses. The RMC with
the particle filter, however, is stochastic and the model prediction can vary from simulation to
simulation, even with the same set of parameter values. Thus for each iteration in parameter
estimation process, we simulated the model 2,000 times to obtain the prediction and its variance.

Also to avoid over-fitting, we assumed that participants have varying values for the coupling
probability $c$ but share values for the sensitivity parameters ($\beta_{c}$, $\beta_{l}$, and
$\beta_{e}$). Also, the sensitivity parameters for the category labels and exemplars are assumed
identical (i.e., $\beta_{l} = \beta_{e}$). Therefore, the estimated parameters are: $c$ for each
participant, and $\beta_{c}$ and $\beta_{l}$ ($=\beta_{e}$) shared across participants.

With the prior distribution $\mathcal{U}(0, 1)$ for the coupling probability and $\mathcal{U}(0.01,
10)$ for the sensitivity parameters, we obtained maximum a posterior (MAP) estimation with the
metric optimization engine (\texttt{http://github.com/Yelp/MOE}).  The estimated parameter values
are saved in ``\texttt{estimated\_parameter.csv}''.


\section{Model-based Estimates}

All the measures below are mean-average of 2,000 simulations with the estimated parameters.


\subsection{Trial-by-trial estimate}

Trial-by-trial estimates are recorded in ``\texttt{trial\_by\_trial\_estimate.csv}.'' Along with
the trial-by-trial data from the experiment, a csv file contains model-based measures.  Four out of
six measures are computed for two phases: a before-feedback phase, where participant saw only pairs
of cues; and a after-feedback phase, where participant saw category and exemplar labels but before
assigning an object to a cluster.  The six measures are described below with column names in the csv
file in parentheses.

\begin{enumerate}

    \item Probability of making a correct response, based on a pair of cues (\texttt{p\_correct}).

    \item Uncertainty in assigning an object to a cluster,
    \begin{enumerate}

        \item the entropy of $p(z_{i} \;\vert\; x_{i})$
            (\texttt{representational\_uncertainty\_before\_feedback}); and

        \item the entropy of $p(z_{i} \;\vert\; x_{i}, \, y_{i},\, y'_{i})$; and
            (\texttt{representational\_uncertainty\_after\_feedback}).

    \end{enumerate}

        This can be thought of as uncertainty about how clearly an object fits in with current
        knowledge. Here, an estimate close to $0$ indicates that an object fits in with current
        knowledge with certainty.

        In previous work, we [Brad] found anterior hippocampus tracked this measure. This
        is not the same thing as a (inverse) familiarity/recognition strength.

    \item Strength of the best matching cluster.
    \begin{enumerate}

        \item the maximum value of $p(z_{i} \;\vert\; x_{i})$
            (\texttt{representational\_strength\_before\_feedback}); and

        \item the maximum value of $p(z_{i} \;\vert\; x_{i}, \, y_{i},\, y'_{i})$
            (\texttt{representational\_strength\_after\_feedback}).

    \end{enumerate}

        This captures how close is the best match in memory. Rather than a global memory match
        signal, this is based on only the best match. Do people retrieve some single best matching
        representation of the current stimulus?

    \item Recognition strength, $p(x_{i})$:

    \begin{enumerate}
        \item (\texttt{recognition\_strength\_before\_feedback}); and
        \item (\texttt{recognition\_strength\_after\_feedback}).
    \end{enumerate}

        This measure is akin to global match, familiarity, recognition strength. In the past, we
        [Brad] have seen posterior hippocampus track this.

    \item Probability of new representation,

    \begin{enumerate}
        \item (\texttt{p\_new\_representation\_before\_feedback}); and
        \item (\texttt{p\_new\_representation\_after\_feedback}).
    \end{enumerate}

        This is a probability of forming a new cluster to accommodate an object. This is a new
        measure that is pretty cool.  It's the probability that the current object is stored
        separately in memory, as opposed to linked/consolidated with an existing representation in
        memory. The latter promotes learning in the model.

    \item Information gained in a trial (\texttt{information\_gain}): This is KL divergence between
    $p(z_{i} \;\vert\; x_{i}, \, y_{i},\, y'_{i})$ and $p(z_{i} \;\vert\; x_{i})$.  This measure
    gets at surprise from learning and error correction.

\end{enumerate}


\subsection{Similarity estimate for RSA}

For the RSA measures, there are two sensible ways to compute the matrices, so we computed both. I
[Brad] am not sure there is a reason to favor one over the other. Hopefully, they both do the same
thing in analyses more or less.  This is similarity between pairs of cues ($x_{i}$ and $x_{j}$
below), and category and exemplar labels are not considered in this measure. They are stored in
``\texttt{similarity.csv}.''

\begin{enumerate}

    \item Vector cosine between $p(z_{i} \;\vert\; x_{i})$ and $p(z_{j} \;\vert\; x_{j})$
    (\texttt{vector\_cosine}); and

    \item Probability that $x_{i}$ and $x_{j}$ are assigned to the same cluster
    (\texttt{p\_same\_representation}).

\end{enumerate}

\end{document}
