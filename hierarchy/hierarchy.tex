% \documentclass[11pt,a4paper]{article}
% \documentclass[man,floatsintext]{apa6}
\documentclass[doc]{apa6}

% \usepackage[margin=2.5cm]{geometry}

\usepackage{graphicx}
\usepackage{subfig}
% \usepackage{subcaption}

\usepackage{amsmath}
\usepackage{amsfonts}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\usepackage[american]{babel}
\usepackage[style=apa,sortcites=true,sorting=nyt,backend=biber]{biblatex}
\DeclareLanguageMapping{american}{american-apa}
\addbibresource{library.bib}


\title{The hierarchical structure is optimal given human cognition.}
% good title, but can revisit later***

\shorttitle{Structure Optimization}
\author{Takao Noguchi, Brad Love}
\affiliation{Department of Experimental Psychology, University College London}

\abstract{%

    Environments surrounding people are often hierarchically structured: a single object usually
    fits into a series of progressively more general categories (e.g., a terrier, dog, and animal).
    Given the prevalence of this hierarchical structure, previous studies often assumed that
    knowledge representation is also hierarchical, although empirical evidence does not provide a
    clear support. In this contribution, we demonstrate that neither the environment nor conceptual
    representations need to be hierarchically structured for people to prefer the hierarchical
    structure: the hierarchical structure enables people to make the most accurate inference and
    should be preferred, even when knowledge representation is flat. This optimality is most
    pronounced when knowledge is represented with clusters of observed objects.  Further, the
    cluster representation naturally leads to the effects of learning order, which explains
    mechanisms behind empirical findings: in particular, the age of acquisition effects and the
    basic level advantage.

}


\authornote{%

    Word count: 3010.

    Last updated: \today.

}


\begin{document}

\maketitle

Even informal observation of everyday categorization reveals that many objects fit into a number of
categories. A single object might be called a terrier, dog, mammal or animal. This hierarchical
structure of categories --- a sequence of progressively larger categories --- has been suggested as
a universal property of category structure across cultures \parencite{Berlin1992a, Atran1998a}.
Given the wide-spread adaptation of the hierarchical structure, it is tempting to assume that
knowledge is hierarchically represented. This assumption of hierarchical representation, indeed,
often underlies theoretical propositions \parencite[e.g.,][]{Tenenbaum2011a}. In this study,
however, we demonstrate that the hierarchical structure is optimal even when knowledge
representation is flat, without the depth represented in the hierarchical structure.

% *** again, i think there is an idea out there that world might be hierarchical. there might be a nice parallel to work in prototype theory. rosch shows people prefer prototypes, so we assume prototype model of concepts, then comes along exemplar models. Likewise, Rosch and others say hierarchy, so people assume some hierarchal organisation, but again that's not necessary.

\subsection*{Hierarchical structure of categories}

\begin{figure}
    \centering

    \subfloat[Hierarchical structure, where dogs share the maximum number of feature values at both
    levels, and categories at the specific level are nested within categories at the general level.] {%

        \includegraphics[]{figure/example_hierarchy.pdf}
    }

    \subfloat[Non-hierarchical structure, where dogs share the maximum number of feature values at
    each level, but categories at the specific level are orthogonal to categories at the general level.]
    {%

        \includegraphics[]{figure/example_nonhierarchy.pdf}
    }

    \vspace{10pt}

    \caption{Example structures with dogs. A rectangle encloses dogs in a category, with a thicker
    rectangle indicating a category at the general level.}

\label{fig:example}
\end{figure}

To begin, let us illustrate the hierarchical structure.  An example hierarchical structure is
illustrated in Figure~\ref{fig:example} (a).  Formally, the hierarchical structure satisfies the two
characteristics: maximization of feature information and containment relation.  First, the
hierarchical structure maximizes the information which objects, $X$, provide about a category
$Y^{(i)}$:
\begin{align}
    I \left( Y^{(i)};\, X \right),
\label{eqn:feature}
\end{align}
which is mutual information between category labels and objects. This feature information is
maximized when all the objects in a category share values on the largest possible number of
features.

The hierarchical structure also satisfies the containment relation, which maximizes the following
measure:
\begin{align}
    \sum_{i=1}^{k-1} \; I \left( Y^{(i)};\, Y^{(i + 1)} \right),
\label{eqn:containment}
\end{align}
which is a sum of mutual information between multiple levels of categories. This containment measure
is maximized when category labels form a partially ordered set: when all the objects in one category
at the specific level fit into the same category at the general level (see Figure~\ref{fig:example} for
examples).

Previous studies have demonstrated that people prefer the hierarchical structure.  When people are
asked to categorize objects in any manner people prefer, for example, people are very likely to
provide hierarchical structure of categories \parencite[e.g.,][]{Rosch1976a}.  Given the wide-spread
preference for hierarchical structure of categories, it has been argued that knowledge is likely
represented with hierarchy \parencite[e.g.,][]{Markman1984a, Markman1989a}.
\textcite{Markman1989a}, for example, argues that people learn to hierarchically represent knowledge
as they accumulate knowledge \parencite[see also][]{Vygotsky1962a, Inhelder1964a}.

This assumption of hierarchical representation has been underlying theoretical propositions in
cognitive science. For example, a mathematical model has been proposed to explain how people could
learn to hierarchically represent knowledge \parencite{Kemp2008a}, and an inference drawn with this
model correlates well with inference people make \parencite{Kemp2009a}.  The assumption of
hierarchical representation also underlies theories in many other domains within cognitive science
(e.g., inference \parencite{Osherson1990a}, memory \parencite{Bower1969a, Glass1975a}, reasoning
\parencite{Collins1989a, Shastri1993a}, and word learning \parencite{Xu2007a}).

The assumption of hierarchical representation, however, is not well supported with empirical
evidence \parencite[see][for review]{Murphy1997a}. \textcite{Sloman1998a}, for example, report that
when reasoning and making inferences with the hierarchical structure, people often neglect the
containment relation, that all the objects in one category at the specific level fit into the same
category at the general level.

In this study, we step back and consider the possibility that preference for hierarchy is not an
indication of hierarchal representation.  In particular, we explore models of category learning that
do not assume the hierarchal structure and to foreshadow, we find these non-hierarchical models
prefer the hierarchical structure too, searching through the space of all possible structures.
Thus, we conclude that much of the previous decades of research on knowledge representation do not
bear on whether knowledge is hierarchically represented.  Instead, our results suggest continuity
between lower level tasks used in lab where knowledge is not hierarchical with higher-level theory
about the nature of complex semantic representations.

%****we
%probably should also mention the semantic verification time literature that shows faster to say a
%chicken is an animal rather than bird as evidence that the field has been grappling with these
%issues for decades, but still ascribes to the logic that performance for or against (in this case
%against) hierarchy is evidence for its existence in mind. we blow up that logic. the point is that
%people are arguing both sides of issues with measures that might not tell us much.


\subsection*{Models of human cognition}

Unlike models of knowledge representation discussed above, many cognitive models of category
learning do not assume the hierarchical structure. Here, we discuss two of the dominant approaches:
clustering and exemplar models. Clustering models assume that people represent knowledge as clusters
of the observed objects \parencite[e.g.,][]{Anderson1991a, Love2004a, Sanborn2010a}. Every time a
new object is observed, the new object is assigned to an existing cluster with similar objects (see
Figure~\ref{fig:cluster} for an example). If none of the existing clusters contains sufficiently
similar objects, a new cluster is created to host the new object.  Then using the knowledge
represented as clusters, an inference is drawn from the observed objects in the cluster.  If a new
object is assigned to a cluster predominantly with terriers, for example, the new object is
considered to be likely to be a terrier.

\begin{figure}
    \centering

    \includegraphics[]{figure/example_cluster.pdf}
    \vspace{6pt}

    \caption{Example clusters. An ellipse encloses dogs in a cluster. A new observation is assigned
    to a cluster which contains most similar dogs.}

\label{fig:cluster}
\end{figure}

Formally, the probability that Object $x$ is inferred as an instance of Category $w$ at Level $i$ is
expressed as follows:
\begin{align}
    p(y^{(i)} = w\; \vert \; x) = \sum_{k \in \mathbb{Z}}
    p(y^{(i)} = w \; \vert \; z = k)
    \;
    p(z = k \; \vert \; x).
\end{align}
Here, $\mathbb{Z}$ is a set of all the possible clusters. The probability of category label,
$p(y^{(i)} = w \; \vert \; z = k)$, signifies drawing inference with clusters: this probability is
higher when more object in Cluster $k$ fit into Category $w$. Also, the probability of a cluster,
$p(z = k \; \vert \; x)$, signifies knowledge representation: this probability is higher when
objects in Cluster $k$ is more similar to Object $x$. We first discuss how an inference can be
improved with clusters, and then address how the improvement depends on knowledge representation.

\subsubsection*{Inference}

%****for here and above, best to anchor in some real-world examples.. it only takes a sentence or two to keep the reader onboard and not get them lost in abstractions (e.g., paragraph below). reviewers are lame too, as we know. your figure does it later, but i would have some real-world one too, like one real-world category for which it's easy to draw infernces and one for which it is difficult.

First, an inference can be more accurate when the probability of category label given a cluster is
optimized. In particular, $p(y^{(i)} = w \; \vert \; z = k)$ approaches $1$, with more objects in
Cluster $k$ fitting into Category $w$. Thus, an inference can be most accurate when the cluster
structure mirrors the category structure. Since objects which share values tend to be assigned to
the same cluster, an inference is more accurate when objects in the same category share values on
more features. When objects in the same category share values on the maximum number of dimensions,
the structure maximizes the feature information (Equation~\ref{eqn:feature}).

Also to allow an accurate inference across multiple levels of categories, objects in the same
cluster have to fit into the same categories at both general and specific levels.  With the cluster
structure illustrated in Figure~\ref{fig:cluster}, for example, an accurate inference can be made
for the small/large dog categories at the general level, and the prick/drop ear categories at the
specific level (see Figure~\ref{fig:example} (a)). An inference, however, cannot be accurate when the
category structure at the general level is orthogonal to the category structure at the specific
level: for example, when small/large dogs are distinguished at the general level, but this
distinction are neglected at the specific level (see Figure~\ref{fig:example} (b)).  When all the
objects in a category at the specific level fit into a same category at the general level category,
the category structure maximizes the containment measure (Equation~\ref{eqn:containment}).

\subsubsection*{Cluster structure}

Therefore, the hierarchical structure is expected to be optimal, such that a human learner is most
likely to make an accurate inference across multiple levels of categories.  This optimality is,
however, depends on how clusters are structured.

\begin{figure}
    \centering

    \includegraphics[]{figure/example_exemplar.pdf}
    \vspace{6pt}

    \caption{Exemplar representation, where each object is assigned to its own cluster.}

\label{fig:exemplar}
\end{figure}

Previous research indicates that also psychologically plausible is the exemplar representation
\parencite{Nosofsky1986a, Nosofsky1991a} (see Figure~\ref{fig:exemplar} for an illustration).  With
the exemplar representation, each cluster contains a single object, and an inference is based on one
of the most similar among the observed objects.  If an object is most similar to an observed object
labeled as a terrier, for example, the object is most likely inferred to be a terrier.  Thus, an
inference is more accurate when similar objects fit into the same category: when the feature
information is maximized.  As the cluster structure cannot follow the category structure, however,
the exemplar representation is insensitive to the containment relation: whether objects in a
category at the specific level fit into the same category at the general level\footnote{We assume
that people do not infer a category label at another level than being asked: when making an
inference on the general category, people do not infer the specific category \parencite[see
however,][]{Nosofsky2015a}.}.

The simulation we report below examined whether the maximization of the feature information and the
containment relation improves inference accuracy. The exemplar and cluster representations are
simulated with the same model but with different parameter values.


\subsection*{Machine teaching}

In the simulation, we adapt machine teaching procedure. Machine teaching identifies the optimal
training set, such that the learner trained on the set achieves the best performance on the testing
set \parencite{Zhu2013a, Patil2014a}.  Thus in the machine teaching, the procedure is conditioned on
the learning model and the category structure.  Here in contrast, we search through possible
structures to identify the optimal structure, such that the learner achieves the best performance.
Thus, our simulation is conditioned on the training set and the learning model.


\section*{Simulation 1}

%*** for the results figure, figure 4, the key thing seems to be that containment helps for clustering model, but not exemplar model. That doesn't jump out from figure because the big visual effect is the rising performance with feature information. Would reversing the focus of figure help? E.g., make the horizontal axis be the containment. In that case, exemplar figure would be self-similar/flat overall across, whereas cluster would rise overall from left to right.

\subsection*{Methods}

We have computed the feature information (Equation~\ref{eqn:feature}) and the containment measure
(Equation~\ref{eqn:containment}) for all the possible category structures with eight objects.  We
coded the three features of eight dogs in Figure~\ref{fig:example} in binary and constrained the
possible category structure, such that the degree of branching is two: the general level has two
categories with four dogs each, and the specific level contains four categories with two dogs each.
Since the ordering of features is exchangeable, the number of possible category structure totals to
3,675.

For each category structure, the model is trained for 10 blocks. Each block involves 16 trials, the
eight objects with a category label at either general or specific level, in a random order.  In a trial
with one level (e.g., the general level), a category label at the other level (e.g., the specific level)
is treated as missing.  After the training blocks, the average inference accuracy was calculated for
each level of categories.  This accuracy was further mean-averaged across the $10^{4}$ simulations
for each category structure (Please refer to Appendix~\ref{appendix:model} for more details of the
    model and the simulation).


\subsection*{Results and Discussion}

\begin{figure}[t!]
    \centering

    \subfloat[Cluster representation. Inference accuracy increases with both feature information and
    containment measure.]
    {%
        \includegraphics[]{./figure/hierarchy_accuracy_cluster.pdf}
    }

    \subfloat[Exemplar representation. Inference accuracy increases with feature information but not
    with containment measure.]
    {%
        \includegraphics[]{./figure/hierarchy_accuracy_exemplar.pdf}
    }

    \caption{The average inference accuracy for each category structure. The levels of categories
    are shown in columns: the left panels illustrate the general level, and the right panels
    illustrate the specific level.  A dot represents mean, and error bar is 95\% empirical interval.
    Each dot is jittered along the horizontal axis for the illustration purposes.}

\label{fig:result}
\end{figure}

For illustration purposes, we scaled the feature information, so that it ranges from 0 to 1 on each
category level. The simulation results are summarized in Figure~\ref{fig:result}. As predicted for
the cluster representation, the inference is more accurate with the feature information and the
containment measure: The highest accuracy is achieved with the largest feature information and the
largest containment measure.

With the exemplar representation, however, the inference is only slightly more accurate with the
feature information. This is because the identical objects are repeatedly presented in the
simulation, and hence, an inference is often based on the identical object, as opposed to the most
similar object among the observed ones. Thus, the similarity between objects tend to have little
impact on inference.  Here, the highest accuracy is achieved with the largest feature information
but the containment measure does not appear to have an impact.

To confirm, we fitted linear regressions on the inference accuracy, which when appropriate, allow
each level to have varying intercepts and slopes. The estimated slopes confirm the above
observations: both feature information and containment measure increases the inference accuracy to a
greater extent with the cluster representation than with the exemplar representation: the
interaction effect is at $\beta=0.15$ (95\% CI [$0.15$, $0.16$]) for the feature information, and at
$\beta=0.02$ (95\% CI [$0.02$, $0.03$]) for the containment measure. Further, the containment
relation has a zero impact on the inference accuracy with the exemplar representation: $\beta=0.00$
(95\% CI [$0.00$, $0.00$]).

Thus as expected, the simulation results show that the hierarchical structure is optimal given human
cognition. This optimality is, however, more pronounced with the cluster representation than with
the exemplar representation. While the cluster representation shows improved inference accuracy with
both feature information and containment relation, the exemplar representation shows improved
inference accuracy only with feature information.


\section*{Simulation 2}

%*** we should discuss figure 6 as well.

The above simulation results confirm that the hierarchical structure is optimal given the cluster
representation. The cluster representation, however, also predicts effects of learning order on
inference accuracy. The predicted effects were tested in Simulation 2.

\begin{figure}
    \centering

    \subfloat[When categories at the general level are learned first, the cluster structure mimics
    the category structure at the general level, allowing an accurate inference at the general level.]
    {%

        \includegraphics[]{figure/example_higher_first.pdf}
    }

    \subfloat[When categories at the specific level are learned first, the cluster structure mimics
    the category structure at the specific level, allowing an accurate inference at the specific level.]
    {%

        \includegraphics[]{figure/example_lower_first.pdf}
    }

    \vspace{10pt}

    \caption{Illustrative cluster structures for each learning order. An ellipse encloses dogs in a
    cluster.}

\label{fig:learning_order}
\end{figure}

The predicted effects of learning order are illustrated in Figure~\ref{fig:learning_order}. As the
cluster assignment of an object considers its category label as well as the object's features,
objects from the same category tend to be perceived similar and fit into the same cluster. As a
result, the cluster structure at first tends to follow the category structure learned at first.
As subsequent learning at another category level builds upon this initial cluster structure, the
cluster structure cannot follow as closely the category structure learned later. Consequently, an
inference tends to be more accurate at the category level learned at first.

With the exemplar representation, however, each object is assigned to its own cluster, regardless of
learning order. Thus, we expect effects of learning order with the cluster representation but not
with the exemplar representation.


\subsection*{Methods}

Simulation 2 employs the almost identical methods to Simulation 1, except that we only tested the
hierarchical structures with two possible learning orders: general-first and specific-first. Also, a
training block in Simulation 2 presents the eight objects in a random order with a category label at
either general or specific level. Then, the learning order of general-first involves 10 training
blocks with the general level first, followed by 10 training blocks with the specific level. This
order is reversed for the learning order of specific-first.

\subsection*{Results and Discussion}

\begin{figure}[t!]
    \centering

    \subfloat[Cluster representation. An inference tends to be more accurate at the level learned at
    first.]
    {%
        \includegraphics[]{./figure/order_accuracy_cluster.pdf}
    }

    \subfloat[Exemplar representation. An inference tends to be more accurate when the specific
    level is learned at first, but the effect appears to be minor. The difference is less than
    $.01$ at both levels.]
    {%
        \includegraphics[]{./figure/order_accuracy_exemplar.pdf}
    }

    \vspace{10pt}

    \caption{The average inference accuracy for each learning order.  The levels of categories are
    shown in columns: the left panels illustrate the general level, and the right panels illustrate
    the specific level.   A dot represents mean, and error bar is 95\% empirical interval.}

\label{fig:result2}
\end{figure}

Figure~\ref{fig:result2} illustrates the average inference accuracy for each learning order. This
figure shows that with the cluster representation, an inference tends to be more accurate at the
level learned at first.  The top left panel in Figure~\ref{fig:result2}, for example, shows that
when the categories at the general level are learned at first, an inference is more accurate at the
general level than when the same categories are learned later. With the exemplar representation, in
contrast, the inference accuracy does not appear much influenced by the learning order: the
difference in accuracy is less than $0.005$.

To confirm, we fit mixed-effect linear regressions to the inference accuracy. The estimated slopes
confirm the above observations: the learning order has a larger impact with the cluster
representation than with the exemplar representation, as indicated by the interaction effect
($\beta=0.08$, 95\% CI [$0.08$, $0.08$]). With the cluster representation, the learning order has
different effect at each level ($\beta=0.08$, 95\% CI [$0.08$, $0.08$]). On the other hand with the
exemplar representation, the learning order does not have a tangible effect ($\beta=0.00$, 95\%
CI [$0.00$, $0.00$]).

These results confirm our predictions: with the cluster representation, learning is built upon the
existing cluster representation. The cluster representation tends to follow the category structure
learned at first.  This cluster structure carries over to the subsequent learning, and as a result,
an inference tends to be more accurate at the level which is learned first.


\section*{General Discussion}

Previous studies within cognitive science have shown widespread preference for hierarchical
structure \parencite[e.g.,][]{Rosch1976a}. This prevailing preference of hierarchical structure has
led researchers to assume that knowledge is hierarchically represented
\parencite[e.g.,][]{Markman1984a, Markman1989a}.  This assumption of hierarchical representation has
underlay theories in many domains within cognitive science.

Although we do not argue against the possibility that knowledge is hierarchically represented, our
simulation results suggest that how people categorize objects may not necessarily correspond to how
knowledge is psychologically represented. Our results indicate that the preference for the
hierarchical structure is not necessarily due to the hierarchical representation. Even with the
cluster representation, which does not distinguish general and specific levels, the hierarchical
structure is optimal and should be preferred. Thus, this study offers an alternative interpretation
of the wide adaptation of hierarchical structure: the adaptation can be seen as evidence for the
cluster representation over the exemplar representation.

In addition, the results from Simulation 2 highlight a mechanism behind the age-of-acquisition
effects \parencite{Gerhand1998a, Morrison1995a}: words that are acquired earlier in childhood are
processed more accurately than words that are acquired later in life. Our results show that a
category structure learned at first tends to shape the knowledge representation, allowing a more
accurate inference.

This initial representation underlies subsequent learning, which further explains the basic level
advantage \parencite{Mervis1981a, Rosch1976a}, where an inference people make is generally more
accurate at the basic level (e.g., dog) than at a more general (e.g., mammal) or more specific level
(e.g., terrier). Our results provide the explanation that the basic level advantage may be a
consequence of learning order. Indeed, previous research has demonstrated that categories at the
basic level are learned earlier at the childhood than at other levels \parencite{Berlin1973a,
Brown1958a, Horton1980a, Mervis1982a}.

In addition, the simulation method we used complements machine teaching \parencite{Zhu2013a}. Our
simulation identifies the structure of objects which is best for human cognition. Thus for example,
a retailer could use the same procedure to identify the best product categories to present to
consumers. Such categories would best-fit consumers' cognition and may help consumers in finding the
products which best suit their needs.


\printbibliography{}

\appendix

\section{Details of Simulation with Rational Model of Cognition}
\label{appendix:model}

Suppose a learner has observed $n - 1$ objects $\left\{x_{1}, x_{2}, \dots, x_{n - 1}\right\}$ with
corresponding category labels $\left\{y_{1}, y_{2}, \dots, y_{n - 1}\right\}$.  Each of these
objects fits into a cluster. The cluster label for the $i$th object is denoted as $z_{i}$.

\subsection{Drawing an inference}

Then, the probability that the $n$th object fits into category $w$ is expressed as follows:
\begin{align}
    p(y_{n} = w \; \vert \; x_{n})
    &= \sum_{k \in \mathbb{Z}} p(z_{n} = k \; \vert \; x_{n}) \; p(y_{n} = w \; \vert \; z_{n} = k) \notag\\
    &= \sum_{k \in \mathbb{Z}} \; \frac{p(z_{n} = k) \; p(x_{n} \;\vert\; z_{n} = k)}{p(x_{n})} \; p(y_{n} = w \; \vert \; z_{n} =
    k) \notag\\
    &= \sum_{k \in \mathbb{Z}} \; \frac{p(z_{n} = k) \; p(x_{n} \;\vert\; z_{n} = k)}{\sum_{s \in
    \mathbb{Z}} \; p(z_{n} = s) \; p(x_{n} \;\vert\; z_{n} = s)} \; p(y_{n} = w \; \vert \; z_{n} = k).
\label{eqn:inference}
\end{align}
Here, $\mathbb{Z}$ is a set of all the possible clusters to which the $n$th object can be assigned.
The three terms in Equation~\ref{eqn:inference} are described below in turn.

First, the probability that the $n$th object fits into cluster $k$ is given by:
\begin{align}
    p(z_{n} = k) = \left\{
        \begin{array}{rcl}
            \displaystyle \frac{c\,m_{k}}{(1 - c) + c\,(n - 1)} & \mbox{if} & m_{k} > 0\\
            \\
            \displaystyle \frac{(1 - c)}{(1 - c) + c\,(n - 1)} & \mbox{if} & m_{k} = 0
        \end{array}
    \right.
\label{eqn:prior}
\end{align}
where $c$ is a parameter called the coupling probability and $m_{k}$ is the number of objects
assigned into cluster $k$.

Following \textcite{Anderson1991a} and \textcite{Sanborn2010a}, we assume that an object has
independent dimensions. Therefore,
\begin{align}
    p(x_{n} \; \vert \; z_{n} = k) = \prod_{d \in D} p(x_{n,d} \; \vert \; z_{n} = k),
\label{eqn:feature1}
\end{align}
where $D$ is a set of dimensions in which an object is described.  The above term is computed with
\begin{align}
    p(x_{n,d} = v \; \vert \; z = k) = \frac{B_{v,d} + \beta_{c}}{m_{k} + J_{d} \, \beta_{c}},
\label{eqn:feature2}
\end{align}
where $B_{v,d}$ is the number of objects in cluster $k$ with value of $v$ on dimension $d$, and
$J_{d}$ is the number of values which an object can take on dimension $d$. Parameter $\beta_{c}$
determines knowledge representation, as discussed below.

Similarly, the probability that the $n$th object has category label $w$, given a cluster, is given by:
\begin{align}
    p(y_{n} = w \; \vert \; z = k) = \frac{B_{w} + \beta_{l}}{B_{.} + J \, \beta_{l}},
\label{eqn:label}
\end{align}
where $B_{w}$ is the number of observed objects with category label $w$ in cluster $k$, $B_{.}$ is
the number of object in cluster $k$, and $J$ is the number of category labels. Also, parameter
$\beta_{l}$ determines knowledge representation, as discussed below.


\subsection{Learning}

The learning is equivalent to assigning an object into a cluster. The probability that an object is
assigned to cluster $k$ is computed as
\begin{align}
    p(z_{n} = k \;\vert\; x_{n},\, y_{n}) \propto
    p(z_{n} = k)
    \;
    p(x_{n} \;\vert\; z_{n} = k)
    \;
    p(y_{n} \;\vert\; z_{n} = k).
\label{eqn:learning}
\end{align}
This is computed with Equations~\ref{eqn:prior},~\ref{eqn:feature1} and~\ref{eqn:label}.
Additionally, this cluster assignment is conducted using the sequential Monte Carlo with one
particle, which produces behavior much like human \parencite{Sanborn2010a}.


\subsection{Knowledge representation}

With the above specification, knowledge representation is determined by values for parameter
$\beta$.  For the cluster representation, we used $\beta_{f}=1.0$ and $\beta_{l}=0.5$. These values
are among the best fitting values to human performance \parencite{Sanborn2010a}.

For the exemplar representation, we used small values of $\beta$ ($\beta_{f}=0.001$ and
$\beta_{l}=0.001$) during the training, ensuring that a cluster can only contain identical objects.
Inference based on such small $\beta$ is, however, often deterministic, and to allow more
probabilistic inference, we used a larger value for $\beta$ ($\beta_{f}=1.0$ and $\beta_{l}=5.0$)
during the testing.

For both representations, the coupling probability $c$ is at $0.5$ during the training blocks and at
$1.0$ during the testing blocks. These coupling probabilities prevent a new cluster from being
created and ensure that an inference is not made with random guessing during the testing.

% In machine learning literature, the rational model of categorization is often called Dirichlet
% processes mixture model \parencite{Antoniak1974a, Ferguson1983a}.

\end{document}
